# c (iii)
boot::boot.ci(b_kurt,type='perc')
#################
# First let us create our estimator
theta.hat <- function(sample){
nsize <- length(sample)
return (((nsize-1)/nsize)*var(sample))
}
# Set the number of bootstrap samples R
R <- 9999
# create a vector for sampling distribution
theta.hat.dist <- rep(0, R)
# do the bootstrap to get the sampling distribution
for (boot in 1:R){
# get sample of size n from F hat.
x.star <- sample(obs.data, n, replace = TRUE)
# get the estimated value from the estimator
theta.hat.dist[boot] <- theta.hat(x.star)
}
# create the plug-in estimator function
g <- function(x, x_bar){
(x - x_bar)^2
}
# Get the expected value of the estimator from bootstrap
mu.Fhat <- mean(theta.hat.dist)
# Get the plug-in estimator
theta.Fhat <- sum(sapply(obs.data, g, x_bar = mean(obs.data)))/n
# Compute the bias as the difference
bias.boot <- mu.Fhat - theta.Fhat
bias.boot
#################
# First let us create our estimator
theta.hat <- function(sample){
nsize <- length(sample)
return (((nsize-1)/nsize)*var(sample))
}
# Set the number of bootstrap samples R
R <- 9999
# create a vector for sampling distribution
theta.hat.dist <- rep(0, R)
# do the bootstrap to get the sampling distribution
for (boot in 1:R){
# get sample of size n from F hat.
x.star <- sample(obs.data, n, replace = TRUE)
# get the estimated value from the estimator
theta.hat.dist[boot] <- theta.hat(x.star)
}
# create the plug-in estimator function
g <- function(x, x_bar){
(x - x_bar)^2
}
# Get the expected value of the estimator from bootstrap
mu.Fhat <- mean(theta.hat.dist)
# Get the plug-in estimator
theta.Fhat <- sum(sapply(obs.data, g, x_bar = mean(obs.data)))/n
# Compute the bias as the difference
bias.boot <- mu.Fhat - 1 #theta.Fhat
bias.boot
library(boot)
library(moments)
# b
# Observed data
set.seed(42)
n <- 100
obs.data <- rnorm(n, mean = 0, sd = 1)
R <- 9999
# Evaluation function
sample.var <- function (x, d){
nsize = length(x)
return(((nsize-1)/nsize)*var(x[d]))
}
# Obtain the bootstrap resamples
b <- boot::boot(obs.data, sample.var, R)
b
#################
# First let us create our estimator
theta.hat <- function(sample){
nsize <- length(sample)
return (((nsize-1)/nsize)*var(sample))
}
# Set the number of bootstrap samples R
R <- 9999
# create a vector for sampling distribution
theta.hat.dist <- rep(0, R)
# do the bootstrap to get the sampling distribution
for (boot in 1:R){
# get sample of size n from F hat.
x.star <- sample(obs.data, n, replace = TRUE)
# get the estimated value from the estimator
theta.hat.dist[boot] <- theta.hat(x.star)
}
# create the plug-in estimator function
g <- function(x, x_bar){
(x - x_bar)^2
}
# Get the expected value of the estimator from bootstrap
mu.Fhat <- mean(theta.hat.dist)
# Get the plug-in estimator
theta.Fhat <- sum(sapply(obs.data, g, x_bar = mean(obs.data)))/n
# Compute the bias as the difference
bias.boot <- mu.Fhat - theta.Fhat
bias.boot
#################
# First let us create our estimator
theta.hat <- function(sample){
nsize <- length(sample)
return (((nsize-1)/nsize)*var(sample))
}
# Set the number of bootstrap samples R
R <- 9999
# create a vector for sampling distribution
theta.hat.dist <- rep(0, R)
# do the bootstrap to get the sampling distribution
for (boot in 1:R){
# get sample of size n from F hat.
x.star <- sample(obs.data, n, replace = TRUE)
# get the estimated value from the estimator
theta.hat.dist[boot] <- theta.hat(x.star)
}
# create the plug-in estimator function
g <- function(x, x_bar){
(x - x_bar)^2
}
# Get the expected value of the estimator from bootstrap
mu.Fhat <- mean(theta.hat.dist)
# Get the plug-in estimator
theta.Fhat <- sum(sapply(obs.data, g, x_bar = mean(obs.data)))/n
# Compute the bias as the difference
bias.boot <- mu.Fhat - theta.Fhat
bias.boot
# c (i)
# Estimator
sigma.hat <- function(sample){
nsize <- length(sample)
return (((nsize-1)/nsize)*var(sample))
}
kurt_fn <- function (sample){
sample_mean = mean(sample)
sigma_hat = sigma.hat(sample)
n <- length(sample)
return (sum((sample - sample_mean) ^ 4) / (n * sigma_hat ^ 2))
}
k_hat <- kurt_fn(obs.data)
k_hat
# b
# Observed data
set.seed(42)
n <- 100
obs.data <- rnorm(n, mean = 0, sd = 1)
R <- 9999
# Evaluation function
sample.var <- function (x, d){
nsize = length(x)
return(((nsize-1)/nsize)*var(x[d]))
}
# Obtain the bootstrap resamples
b <- boot::boot(obs.data, sample.var, R)
b
########## kurtosis
#################
# First let us create our estimator
sigma.hat <- function(sample){
nsize <- length(sample)
return (((nsize-1)/nsize)*var(sample))
}
kurt_fn <- function (sample){
sample_mean = mean(sample)
sigma_hat = sigma.hat(sample)
n <- length(sample)
return (sum((sample - sample_mean) ^ 4) / (n * sigma_hat ^ 2))
}
# Set the number of bootstrap samples R
R <- 9999
# create a vector for sampling distribution
theta.hat.dist <- rep(0, R)
# do the bootstrap to get the sampling distribution
for (boot in 1:R){
# get sample of size n from F hat.
x.star <- sample(obs.data, n, replace = TRUE)
# get the estimated value from the estimator
theta.hat.dist[boot] <- kurt_fn(x.star)
}
# Get the expected value of the estimator from bootstrap
mu.Fhat <- mean(theta.hat.dist)
# Get the plug-in estimator
#theta.Fhat <- sum(sapply(obs.data, g, x_bar = mean(obs.data)))/n
k_hat <- kurt_fn(obs.data)
k_hat
# Compute the bias as the difference
bias.boot <- mu.Fhat - k_hat
bias.boot
# c (i)
# Estimator
sigma.hat <- function(sample){
nsize <- length(sample)
return (((nsize-1)/nsize)*var(sample))
}
kurt_fn <- function (sample){
sample_mean = mean(sample)
sigma_hat = sigma.hat(sample)
n <- length(sample)
return (sum((sample - sample_mean) ^ 4) / (n * sigma_hat ^ 2))
}
k_hat <- kurt_fn(obs.data)
k_hat
# Evaluation function
sample.kurt <- function (x, d){
nsize = length(x)
return(kurt_fn(x[d]))
}
b_kurt <- boot::boot(obs.data, sample.kurt, R)
b_kurt
# c (i)
# Estimator
sigma.hat <- function(sample){
nsize <- length(sample)
return (((nsize-1)/nsize)*var(sample))
}
kurt_fn <- function (sample){
sample_mean = mean(sample)
sigma_hat = sigma.hat(sample)
n <- length(sample)
return (sum((sample - sample_mean) ^ 4) / (n * sigma_hat ^ 2))
}
k_hat <- kurt_fn(obs.data)
k_hat
# Evaluation function
sample.kurt <- function (x, d){
nsize = length(x)
return(kurt_fn(x[d]))
}
b_kurt <- boot::boot(obs.data, sample.kurt, R)
b_kurt
# Set the number of bootstrap samples R
R <- 9999
# create a vector for sampling distribution
theta.hat.dist <- rep(0, R)
# do the bootstrap to get the sampling distribution
for (boot in 1:R){
# get sample of size n from F hat.
x.star <- sample(obs.data, n, replace = TRUE)
# get the estimated value from the estimator
theta.hat.dist[boot] <- kurt_fn(x.star)
}
# Get the expected value of the estimator from bootstrap
mu.Fhat <- mean(theta.hat.dist)
# Get the plug-in estimator
#theta.Fhat <- sum(sapply(obs.data, g, x_bar = mean(obs.data)))/n
k_hat <- kurt_fn(obs.data)
k_hat
# Compute the bias as the difference
bias.boot <- mu.Fhat - k_hat
bias.boot
# create a vector for sampling distribution
theta.hat.dist <- rep(0, R)
# do the bootstrap to get the sampling distribution
for (boot in 1:R){
# get sample of size n from F hat.
x.star <- sample(obs.data, n, replace = TRUE)
# get the estimated value from the estimator
theta.hat.dist[boot] <- kurt_fn(x.star)
}
# Get the expected value of the estimator from bootstrap
mu.Fhat <- mean(theta.hat.dist)
# Get the plug-in estimator
#theta.Fhat <- sum(sapply(obs.data, g, x_bar = mean(obs.data)))/n
k_hat <- kurt_fn(obs.data)
# Compute the bias as the difference
bias.boot <- mu.Fhat - k_hat
bias.boot
########## kurtosis
#################
# First let us create our estimator
sigma.hat <- function(sample){
nsize <- length(sample)
return (((nsize-1)/nsize)*var(sample))
}
kurt_fn <- function (sample){
sample_mean = mean(sample)
sigma_hat = sigma.hat(sample)
n <- length(sample)
return (sum((sample - sample_mean) ^ 4) / (n * sigma_hat ^ 2))
}
# Set the number of bootstrap samples R
R <- 9999
# create a vector for sampling distribution
theta.hat.dist <- rep(0, R)
# do the bootstrap to get the sampling distribution
for (boot in 1:R){
# get sample of size n from F hat.
x.star <- sample(obs.data, n, replace = TRUE)
# get the estimated value from the estimator
theta.hat.dist[boot] <- kurt_fn(x.star)
}
# Get the expected value of the estimator from bootstrap
mu.Fhat <- mean(theta.hat.dist)
# Get the plug-in estimator
#theta.Fhat <- sum(sapply(obs.data, g, x_bar = mean(obs.data)))/n
k_hat <- kurt_fn(obs.data)
# Compute the bias as the difference
bias.boot <- mu.Fhat - k_hat
bias.boot
var(obs.data)
sigma.hat(obs.data)
R <- 9999
# Evaluation function
sample.var <- function (x, d){
nsize = length(x)
return(((nsize-1)/nsize)*var(x[d]))
}
# Obtain the bootstrap resamples
b <- boot::boot(obs.data, sample.var, R)
b
boot:boot.ci(b,type='perc')
boot:boot.ci(b,type='perc')
# Obtain the bootstrap resamples
b <- boot::boot(obs.data, sample.var, R)
b
boot:boot.ci(b,type='perc')
boot::boot.ci(b)
k_hat
kurtosis(obs.data)
bias.boot
# Evaluation function
sample.kurt <- function (x, d){
nsize = length(x)
return(kurt_fn(x[d]))
}
b_kurt <- boot::boot(obs.data, sample.kurt, R)
b_kurt
# c (iii)
boot::boot.ci(b_kurt,type='perc')
library(boot)
library(moments)
# Observed data
set.seed(11)
n <- 100
obs_data <- rnorm(n, mean = 0, sd = 1)
########## kurtosis
#################
# First let us create our estimator
sigma.hat <- function(sample){
nsize <- length(sample)
return (((nsize-1)/nsize)*var(sample))
}
#################
# First let us create our estimator
theta.hat <- function(sample){
nsize <- length(sample)
return (((nsize-1)/nsize)*var(sample))
}
# Set the number of bootstrap samples R
R <- 9999
# create a vector for sampling distribution
theta.hat.dist <- rep(0, R)
# do the bootstrap to get the sampling distribution
for (boot in 1:R){
# get sample of size n from F hat.
x.star <- sample(obs_data, n, replace = TRUE)
# get the estimated value from the estimator
theta.hat.dist[boot] <- theta.hat(x.star)
}
# create the plug-in estimator function
g <- function(x, x_bar){
(x - x_bar)^2
}
# Get the expected value of the estimator from bootstrap
mu.Fhat <- mean(theta.hat.dist)
# Get the plug-in estimator
theta.Fhat <- sum(sapply(obs_data, g, x_bar = mean(obs_data)))/n
# Compute the bias as the difference
bias.boot <- mu.Fhat - theta.Fhat
bias.boot
#################
# First let us create our estimator
theta.hat <- function(sample){
nsize <- length(sample)
return (((nsize-1)/nsize)*var(sample))
}
# Set the number of bootstrap samples R
R <- 9999
# create a vector for sampling distribution
theta.hat.dist <- rep(0, R)
# do the bootstrap to get the sampling distribution
for (boot in 1:R){
# get sample of size n from F hat.
x.star <- sample(obs_data, n, replace = TRUE)
# get the estimated value from the estimator
theta.hat.dist[boot] <- theta.hat(x.star)
}
# create the plug-in estimator function
g <- function(x, x_bar){
(x - x_bar)^2
}
# Get the expected value of the estimator from bootstrap
mu.Fhat <- mean(theta.hat.dist)
# Get the plug-in estimator
theta.Fhat <- sum(sapply(obs_data, g, x_bar = mean(obs_data)))/n
# Compute the bias as the difference
bias.boot <- mu.Fhat - theta.Fhat
bias.boot
# Obtain the bootstrap resamples
b <- boot::boot(obs_data, sample.var, R)
b
### Part(iii) - repeat for the more complicated function
## Define range of values for alpha > 1 (defining different annealing schedules
## beta_t = alpha^t*beta_0)
alphas <- c(1.0001, 1.001, 1.005, 1.01, 1.1, 1.5)
## Define range of values for sigma (defining different proposal scales)
sigmas <- c(0.0001, 0.001, 0.01, 0.1, 1, 10)
## Define different colors for plots
cols <- c("red", "blue", "green", "orange", "black", "purple")
#cols <- colors()[100:109]
## Run, plot and save the minimizer
# variable to save the min
N <- 1e5 #2e3
min_value <- 100000
minimizer <- c(0,0)
best_pair <- c(0,0)
for (i in 1:length(alphas)) {
alpha <- alphas[i]
for (j in 1:length(sigmas)) {
sigma <- sigmas[j]
list_out <- simulated_annealing(fn2, c(0, 0), sigma, alpha, niter = N, beta0=1)
min_t <- list_out[[2]][N]
if (min_t < min_value){   # If a smaller value of f obtained save the minimizer and corresponding parameters
min_value <- min_t
minimizer <- list_out[[1]][N,]
best_pair <- c(alpha,sigma)
}
if (j == 1){
plot(list_out[[2]], type='l', col=cols[1], xlab = 't', ylab = 'f(x_t)',main = paste("alpha= ", alpha))
legend(x= "topright", y=0.92, legend=c("sigma=0.001", "sigma=0.01","sigma=0.1", "sigma=1", "sigma=10", "sigma=100"), col = cols,  lty=1, cex=0.8)
}
else{
lines(list_out[[2]], type='l', col=cols[j])
}
}
}
min_value
minimizer
best_pair
source('~/Dropbox/mmd_project_code/ABC_Rcode/gandk_wsmc.R')
library(glue)
source('~/Dropbox/mmd_project_code/ABC_Rcode/gandk_wsmc.R')
source('~/Dropbox/mmd_project_code/ABC_Rcode/gandk_wsmc.R')
source('~/Dropbox/mmd_project_code/ABC_Rcode/gandk_wsmc.R')
source('~/Dropbox/mmd_project_code/ABC_Rcode/gandk_wsmc.R')
results
source('~/Dropbox/mmd_project_code/ABC_Rcode/mvnormal_wsmc_wasserstein.R')
source('~/Dropbox/mmd_project_code/ABC_Rcode/mvnormal_wsmc_wasserstein.R')
source('~/Dropbox/mmd_project_code/ABC_Rcode/mvnormal_wsmc_wasserstein.R')
results_wasserstein <- results
# sum(results_euclidean$ncomputed)
# sum(results_summary$ncomputed)
sum(results_wasserstein$ncomputed)
#wsmc.euclidean.df <- wsmc_to_dataframe(results_euclidean) %>% filter(step == length(results_euclidean$thetas_history))
#wsmc.summary.df <- wsmc_to_dataframe(results_summary) %>% filter(step == length(results_summary$thetas_history))
wsmc.wasserstein.df <- wsmc_to_dataframe(results_wasserstein) %>% filter(step == length(results_wasserstein$thetas_history))
wsmc.wasserstein.df$X1
wsmc.wasserstein.df$X2
wsmc.wasserstein.df$X3
wsmc.wasserstein.df$X4
string <- paste0("/Users/HaritaDellaporta/Dropbox/mmd_project_code/results/Gaussian_location_model/WABC/thetas_mabc_outl_", n_cont, "_run_", r, "_dim_",d,".csv")
write.csv(wsmc.wasserstein.df, string)
source('~/Dropbox/mmd_project_code/ABC_Rcode/mvnormal_wsmc_wasserstein.R')
results_wasserstein <- results
# sum(results_euclidean$ncomputed)
# sum(results_summary$ncomputed)
sum(results_wasserstein$ncomputed)
#wsmc.euclidean.df <- wsmc_to_dataframe(results_euclidean) %>% filter(step == length(results_euclidean$thetas_history))
#wsmc.summary.df <- wsmc_to_dataframe(results_summary) %>% filter(step == length(results_summary$thetas_history))
wsmc.wasserstein.df <- wsmc_to_dataframe(results_wasserstein) %>% filter(step == length(results_wasserstein$thetas_history))
string <- paste0("/Users/HaritaDellaporta/Dropbox/mmd_project_code/results/Gaussian_location_model/WABC/thetas_mabc_outl_", n_cont, "_run_", r, "_dim_",d,".csv")
write.csv(wsmc.wasserstein.df, string)
source('~/Dropbox/mmd_project_code/ABC_Rcode/mvnormal_wsmc_wasserstein.R')
results_wasserstein <- results
# sum(results_euclidean$ncomputed)
# sum(results_summary$ncomputed)
sum(results_wasserstein$ncomputed)
#wsmc.euclidean.df <- wsmc_to_dataframe(results_euclidean) %>% filter(step == length(results_euclidean$thetas_history))
#wsmc.summary.df <- wsmc_to_dataframe(results_summary) %>% filter(step == length(results_summary$thetas_history))
wsmc.wasserstein.df <- wsmc_to_dataframe(results_wasserstein) %>% filter(step == length(results_wasserstein$thetas_history))
string <- paste0("/Users/HaritaDellaporta/Dropbox/mmd_project_code/results/Gaussian_location_model/WABC/thetas_mabc_outl_", n_cont, "_run_", r, "_dim_",d,".csv")
write.csv(wsmc.wasserstein.df, string)
source('~/Dropbox/mmd_project_code/ABC_Rcode/run_wabc_experiments.R')
source('~/Dropbox/mmd_project_code/ABC_Rcode/run_gauss.R')
nparticles
source('~/Dropbox/mmd_project_code/ABC_Rcode/mvnormal_wsmc_wasserstein.R')
results_wasserstein <- results
# sum(results_euclidean$ncomputed)
# sum(results_summary$ncomputed)
sum(results_wasserstein$ncomputed)
#wsmc.euclidean.df <- wsmc_to_dataframe(results_euclidean) %>% filter(step == length(results_euclidean$thetas_history))
#wsmc.summary.df <- wsmc_to_dataframe(results_summary) %>% filter(step == length(results_summary$thetas_history))
wsmc.wasserstein.df <- wsmc_to_dataframe(results_wasserstein) %>% filter(step == length(results_wasserstein$thetas_history))
wsmc.wasserstein.df$X1
wsmc.wasserstein.df$X2
wsmc.wasserstein.df$X3
wsmc.wasserstein.df$X4
source('~/Dropbox/mmd_project_code/ABC_Rcode/mvnormal_wsmc_wasserstein.R')
results_wasserstein <- results
# sum(results_euclidean$ncomputed)
# sum(results_summary$ncomputed)
sum(results_wasserstein$ncomputed)
#wsmc.euclidean.df <- wsmc_to_dataframe(results_euclidean) %>% filter(step == length(results_euclidean$thetas_history))
#wsmc.summary.df <- wsmc_to_dataframe(results_summary) %>% filter(step == length(results_summary$thetas_history))
wsmc.wasserstein.df <- wsmc_to_dataframe(results_wasserstein) %>% filter(step == length(results_wasserstein$thetas_history))
wsmc.wasserstein.df$X4
wsmc.wasserstein.df$X1
wsmc.wasserstein.df$X2
source('~/Dropbox/mmd_project_code/ABC_Rcode/gandk_wsmc.R')
